#-*-coding:UTF-8-*-
import net_functions as tu

def alexnet_cnn(x,keep_prob):
    
    with tf.name_scope('alexnet_cnn') as scope:
        with tf.name_scope('alexnet_cnn_conv1') as inner_scope:
            w1=tu.weights([11,11,3,96],name='w1')
            b1=tu.biases(0.0,[96],name='b1')
            conv1=tf.add(tu.conv2d(x,w1,stride=(4,4),padding='SAME'),b1)  #'SAME'不够则填充，‘VALID’多余则去掉
            conv1=tu.relu(conv1)
            norm1=tu.lrn(conv1,depth_radius=2,bias=1.0,alpha=2e-5,beta=0.75)
            pool1=tu.max_pool2d(norm1,kernel=[1,3,3,1],stride=[1,2,2,1],padding='VALID')
 
        with tf.name_scope('alexnet_cnn_conv2') as inner_scope:
            w2=tu.weights([5,5,96,256],name='w2')
            b2=tu.biases(0.0,[256].name='b2')
            conv2=tf.add(tu.conv2d(pool1,w2,stride=(1,1),padding='SAME'),b2)  #'SAME'不够则填充，‘VALID’多余则去掉
            conv2=tu.relu(conv2)
            norm2=tu.lrn(conv2,depth_radius=2,bias=1.0,alpha=2e-5,beta=0.75)
            pool2=tu.max_pool2d(norm2,kernel=[1,3,3,1],stride=[1,2,2,1],padding='VALID')
         with tf.name_scope('alexnet_cnn_conv3') as inner_scope:
            w3=tu.weights([3,3,256,384],name='w3')
            b3=tu.biases(0.0,[384].name='b3')
            conv3=tf.add(tu.conv2d(pool2,w3,stride=(1,1),padding='SAME'),b3)  #'SAME'不够则填充，‘VALID’多余则去掉
            conv3=tu.relu(conv3)
         with tf.name_scope('alexnet_cnn_conv4') as inner_scope:
            w4=tu.weights([3,3,384,384],name='w4')
            b4=tu.biases(0.0,[384].name='b4')
            conv4=tf.add(tu.conv2d(conv3,w4,stride=(1,1),padding='SAME'),b4)  #'SAME'不够则填充，‘VALID’多余则去掉
            conv4=tu.relu(conv4)
         with tf.name_scope('alexnet_cnn_conv5') as inner_scope:
            w5=tu.weights([3,3,384,256],name='w5')
            b5=tu.biases(0.0,[256].name='b5')
            conv5=tf.add(tu.conv2d(conv4,w5,stride=(1,1),padding='SAME'),b5)  #'SAME'不够则填充，‘VALID’多余则去掉
            conv5=tu.relu(conv5)
            pool5=tu.max_pool2d(conv5,kernel=[1,3,3,1],stride=[1,2,2,1],padding='VALID')
         
         flattend=tf.reshape(pool5,[-1,6*6*256])#必须把四维张量展开成一维矢量
         with tf.name_scope('alexnet_cnn_conv6') as inner_scope:
            w6=tu.weights([6*6*256,4096],name='w6')
            b6=tu.biases(0.0,[4096],name='b6')
            fc6=tf.add(tf.matmul(flattend,w6),b6)
            fc6=tf.relu(fc6)
            fc6=tf.nn.dropout(fc6,keep_prob)
         with tf.name_scope('alexnet_cnn_conv7') as inner_scope:
            w7=tu.weights([4096,4096],name='w7')
            b7=tu.biases(0.0,[4096],name='b7')
            fc7=tf.add(tf.matmul(fc6,w7),b7)
            fc7=tf.relu(fc7)
            fc7=tf.nn.dropout(fc7,keep_prob)
         with tf.name_scope('alexnet_cnn_output') as inner_scope:
            w8=tu.weights([4096,100],name='w8')
            b8=tu.biases(0.0,[100],name='b8')
            fc8=tf.add(tf.matmul(fc7,w8),b8)
            output=tf.nn.softmax(fc8)

    return softmax


 
         
